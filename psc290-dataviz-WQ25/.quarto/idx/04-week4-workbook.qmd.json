{"title":"Week 4 (Workbook) - Associations","markdown":{"yaml":{"title":"Week 4 (Workbook) - Associations","author":"Emorie D Beck","format":{"html":{"code-tools":true,"code-copy":true,"code-line-numbers":true,"code-link":true,"theme":"united","highlight-style":"tango","df-print":"paged","code-fold":"show","toc":true,"toc-float":true,"self-contained":true,"footer":"PSC 290 - Data Visualization","logo":"https://github.com/emoriebeck/psc290-data-viz-2022/raw/main/01-week1-intro/02-code/02-images/ucdavis_logo_blue.png"}}},"headingText":"loads an RData file, and returns it","containsRefs":false,"markdown":"\n\n```{r, echo = F}\nknitr::opts_chunk$set(echo = TRUE, warning = F, message = F, error = F)\noptions(knitr.kable.NA = '')\n```\n\n```{r, echo = F}\nlibrary(RColorBrewer)\nlibrary(plyr)\nlibrary(broom)\nlibrary(tidyverse)\n```\n\n```{r, eval = F, echo = F}\nwd <- \"/Volumes/Emorie/other projects/selection\"\nloadRData <- function(fileName, obj){\n    path <- sprintf(\"%s/data/sca/%s.RData\", wd, fileName)\n    load(path)\n    get(ls()[grepl(obj, ls())])\n}\n\nsample_fun <- function(x){\n  x2 <- x %>%\n    group_by(study, o_value) %>%\n    nest() %>%\n    ungroup() %>%\n    mutate(data = map(data, \n        ~(.) %>% filter(row_number() %in% sample(1:nrow(.), if(nrow(.) > 500) 500 else nrow(.))))) %>%\n    unnest(data) %>%\n    select(-Trait, -Outcome)\n  x2 <- x2 %>% mutate(study = mapvalues(study, unique(study), paste0(\"Study\", 1:length(unique(study)))))\n}\n\npred_data <- crossing(\n  Trait = c(\"E\", \"A\", \"C\", \"N\", \"O\")\n  , Outcome = \"mortality\"\n  , Moderator = c(\"none\", \"gender\")\n) %>%\n  mutate(file = paste(\"sca\", Trait, Outcome, sep = \"_\")\n         , data = map2(file, \"df1\", loadRData)\n         , data = map(data, sample_fun)) %>%\n  select(-file) \n\npred_data <- pred_data$data[[4]]\n\nsave(pred_data, file = \"/Volumes/Emorie/GitHub/psc290-data-viz-2022/04-week4-associations/04-data/week4-data.RData\")\n```\n\n## The Data\n\n```{r}\nload(url(\"https://github.com/emoriebeck/psc290-data-viz-2022/blob/main/04-week4-associations/04-data/week4-data.RData?raw=true\"))\npred_data\n```\n\n# Part 1 Visualizing Associations Among Quantitative Variables\n\n## Scatterplots\n\n-   Scatterplots are pretty ubiquitous\n-   From a data visualization standpoint, this makes sense\n-   Scatterplots\n    -   show raw data\\\n    -   are common enough that little visualization literacy is needed\n    -   allow for lots of summaries to be placed atop them\n    -   this is why they are our entry point for today\n\n## Scatterplots - Basics\n\n```{r}\npred_data %>% \n  select(study, SID, p_value, SRhealth)\n```\n\nLet's look at a basic scatterplot:\n\n```{r}\npred_data %>% \n  select(study, SID, p_value, SRhealth) %>%\n  ggplot(aes(x = p_value, y = SRhealth)) + \n    geom_point(shape = 21, fill = \"grey80\", color = \"black\", size = 2) + \n    labs(\n      x = \"Agreeableness (POMP; 0-10)\"\n      , y = \"Self-Rated Health (POMP; 0-10)\"\n    ) + \n    theme_classic()\n```\n\nNow let's add a trend line:\n\n```{r}\npred_data %>% \n  select(study, SID, p_value, SRhealth) %>%\n  ggplot(aes(x = p_value, y = SRhealth)) + \n    geom_point(shape = 21, fill = \"grey80\", color = \"black\", size = 2) + \n    geom_smooth(method = \"lm\", size = 3, se = F) + \n    labs(\n      x = \"Conscientiousness (POMP; 0-10)\"\n      , y = \"Self-Rated Health (POMP; 0-10)\"\n    ) + \n    theme_classic()\n```\n\nBut we have multiple studies, so we need to separate them out using `facet_wrap()`\n\n```{r}\npred_data %>% \n  select(study, SID, p_value, SRhealth) %>%\n  filter(!is.na(SRhealth)) %>%\n  ggplot(aes(x = p_value, y = SRhealth)) + \n    geom_point(shape = 21, fill = \"grey80\", color = \"black\", size = 2) + \n    scale_fill_manual(values = c(\"grey80\", \"seagreen4\")) + \n    facet_wrap(~study) +\n    labs(\n      x = \"Conscientiousness (POMP; 0-10)\"\n      , y = \"Self-Rated Health (POMP; 0-10)\"\n    ) + \n    theme_classic()\n```\n\n```{r}\npred_data %>% \n  select(study, SID, p_value, SRhealth) %>%\n  filter(!is.na(SRhealth)) %>%\n  ggplot(aes(x = p_value, y = SRhealth)) + \n    geom_point(shape = 21, fill = \"grey80\", color = \"black\", size = 2, alpha = .25) + \n    geom_smooth(method = \"lm\", size = 3, se = F) + \n    scale_fill_manual(values = c(\"grey80\", \"seagreen4\")) + \n    facet_wrap(~study) +\n    labs(\n      x = \"Conscientiousness (POMP; 0-10)\"\n      , y = \"Self-Rated Health (POMP; 0-10)\"\n    ) + \n    theme_classic()\n```\n\nBut if you remember from your readings, we don't typically want to show associations without some sort of estimate of error, confidence, etc.\n\n```{r}\npred_data %>% \n  select(study, SID, p_value, SRhealth) %>%\n  filter(!is.na(SRhealth)) %>%\n  ggplot(aes(x = p_value, y = SRhealth)) + \n    geom_point(shape = 21, fill = \"grey80\", color = \"black\", size = 2, alpha = .25) + \n    geom_smooth(method = \"lm\", size = 1.5, se = T, color = \"black\") + \n    scale_fill_manual(values = c(\"grey80\", \"seagreen4\")) + \n    facet_wrap(~study) +\n    labs(\n      x = \"Conscientiousness (POMP; 0-10)\"\n      , y = \"Self-Rated Health (POMP; 0-10)\"\n      , title = \"Conscientiousness -- Self-Rated Health Associations Across Samples\"\n    ) + \n    theme_classic()\n```\n\n## Correlations and Correlelograms\n\n-   Understanding associations is always important, but perhaps never more so than when we do descriptives\n\n-   My hot take is that zero-order correlation maatrices should always be included in papers\n\n    -   Someone's meta-analysis will thank you\n\n-   If you're dumping correlations in supplementary materials, then tables are fine\n\n-   But you (and your brain) will thank yourself if you use heat maps or correlelograms to visualize the correlations\n\n    -   (Remember how quickly and preattentively we perceive color and size?)\n\n-   There are `R` packages for this, but where's the fun in that?\n\n-   All right, let's estimate some correlation matrices for each sample.\n\n```{r}\nr_data <- pred_data %>%\n  select(study, p_value, age, gender, SRhealth, smokes, exercise, BMI, education, parEdu, mortality = o_value) %>%\n  mutate_if(is.factor, ~as.numeric(as.character(.))) %>%\n  group_by(study) %>%\n  nest() %>%\n  ungroup() %>%\n  mutate(r = map(data, ~cor(., use = \"pairwise\")))\nr_data\n```\n\n-   The thing is that we know ggplot doesn't like wide form data, which is what `cor()` produces\n\n```{r}\nr_data$r[[1]]\n```\n\n### Reshaping\n\n-   So we need to reshape it in long form\n-   We're going to use a function so we only have to write the code once and can apply it to all the samples\n-   Here's what we'll do:\n    -   remove the lower triangle and the diagonal of the correlation matrix\n    -   make matrix a data frame\n    -   make the row names of the matrix a column\n    -   make the columns long\n    -   factor them to retain order\n\n```{r}\nr_reshape_fun <- function(r){\n  coln <- colnames(r)\n  # remove lower tri and diagonal\n  r[lower.tri(r, diag = T)] <- NA\n  r %>% data.frame() %>%\n    rownames_to_column(\"V1\") %>%\n    pivot_longer(\n      cols = -V1\n      , values_to = \"r\"\n      , names_to = \"V2\"\n    ) %>%\n    mutate_at(vars(V1, V2), ~factor(., coln))\n}\n\nr_data <- r_data %>%\n  mutate(r = map(r, r_reshape_fun))\nr_data$r[[1]]\n```\n\n### Heat Map Time!\n\nThis is, technically, a heat map, but I think we can do better!\n\n```{r}\nr_data$r[[1]] %>%\n  ggplot(aes(\n    x = V1\n    , y = V2\n    , fill = r\n  )) + \n  geom_raster() + \n  theme_minimal()\n```\n\n#### Colors\n\nLet's add some intuitive colors using `scale_fill_gradient2()`\n\n```{r}\nr_data$r[[1]] %>%\n  ggplot(aes(x = V1, y = V2, fill = r)) + \n  geom_raster() + \n  scale_fill_gradient2(\n    limits = c(-1,1)\n    , breaks = c(-1, -.5, 0, .5, 1)\n    , low = \"blue\"\n    , high = \"red\"\n    , mid = \"white\"\n    , na.value = \"white\"\n    ) + \n  theme_minimal()\n```\n\n#### Labels\n\nDo we need axis labels?\n\n```{r}\nr_data$r[[1]] %>%\n  ggplot(aes(x = V1, y = V2, fill = r)) + \n  geom_raster() + \n  scale_fill_gradient2(limits = c(-1,1)\n    , breaks = c(-1, -.5, 0, .5, 1)\n    , low = \"blue\", high = \"red\"\n    , mid = \"white\", na.value = \"white\") + \n  labs(\n    x = NULL\n    , y = NULL\n    , fill = \"Zero-Order Correlation\"\n    , title = \"Zero-Order Correlations Among Variables in Sample 1\"\n    ) + \n  theme_minimal()\n```\n\n#### Theme Elements\n\nLet's fix the theme elements. So close!\n\n```{r}\nr_data$r[[1]] %>%\n  ggplot(aes(x = V1, y = V2, fill = r)) + \n  geom_raster() + \n  scale_fill_gradient2(limits = c(-1,1)\n    , breaks = c(-1, -.5, 0, .5, 1)\n    , low = \"blue\", high = \"red\"\n    , mid = \"white\", na.value = \"white\") + \n  labs(\n    x = NULL\n    , y = NULL\n    , fill = \"Zero-Order Correlation\"\n    , title = \"Zero-Order Correlations Among Variables\"\n    , subtitle = \"Sample 1\"\n    ) + \n  theme_classic() + \n  theme(\n    legend.position = \"bottom\"\n    , axis.text = element_text(face = \"bold\")\n    , axis.text.x = element_text(angle = 45, hjust = 1)\n    , plot.title = element_text(face = \"bold\", hjust = .5)\n    , plot.subtitle = element_text(face = \"italic\", hjust = .5)\n    , panel.background = element_rect(color = \"black\", size = 1)\n  )\n```\n\n#### Finishing Touches!\n\nLet's fix the theme elements. So close!\n\n```{r}\nr_data$r[[1]] %>%\n  ggplot(aes(x = V1, y = V2, fill = r)) + \n  geom_raster() + \n  geom_text(aes(label = round(r, 2))) + \n  scale_fill_gradient2(limits = c(-1,1)\n    , breaks = c(-1, -.5, 0, .5, 1)\n    , low = \"blue\", high = \"red\"\n    , mid = \"white\", na.value = \"white\") + \n  labs(\n    x = NULL\n    , y = NULL\n    , fill = \"Zero-Order Correlation\"\n    , title = \"Zero-Order Correlations Among Variables\"\n    , subtitle = \"Sample 1\"\n    ) + \n  theme_classic() + \n  theme(\n    legend.position = \"bottom\"\n    , axis.text = element_text(face = \"bold\")\n    , axis.text.x = element_text(angle = 45, hjust = 1)\n    , plot.title = element_text(face = \"bold\", hjust = .5)\n    , plot.subtitle = element_text(face = \"italic\", hjust = .5)\n    , panel.background = element_rect(color = \"black\", size = 1)\n  )\n```\n\n### Correlelogram\n\nA correlelogram is basically a heat map that uses size in addition to color.\n\n```{r}\nr_data$r[[1]] %>%\n  ggplot(aes(x = V1, y = V2, color = r, size = abs(r))) + \n  geom_point() + \n  theme_classic()\n```\n\n#### Improvements\n\nWe're going to skip the steps we took with a heat map. So close! Just need to get rid of that size legend.\n\n```{r}\nr_data$r[[1]] %>%\n  ggplot(aes(x = V1, y = V2, fill = r, size = abs(r))) + \n  geom_point(shape = 21) + \n  scale_fill_gradient2(limits = c(-1,1)\n    , breaks = c(-1, -.5, 0, .5, 1)\n    , low = \"blue\", high = \"red\"\n    , mid = \"white\", na.value = \"white\") + \n  scale_size_continuous(range = c(3,14)) + \n  labs(\n    x = NULL\n    , y = NULL\n    , fill = \"Zero-Order Correlation\"\n    , title = \"Zero-Order Correlations Among Variables\"\n    , subtitle = \"Sample 1\"\n    ) + \n  theme_classic() + \n  theme(\n    legend.position = \"bottom\"\n    , axis.text = element_text(face = \"bold\")\n    , axis.text.x = element_text(angle = 45, hjust = 1)\n    , plot.title = element_text(face = \"bold\", hjust = .5)\n    , plot.subtitle = element_text(face = \"italic\", hjust = .5)\n    , panel.background = element_rect(color = \"black\", size = 1)\n  )\n```\n\n#### Legend\n\n-   To do this, we'll use the `guides()` function!\n\n```{r}\nr_data$r[[1]] %>%\n  ggplot(aes(x = V1, y = V2, fill = r, size = abs(r))) + \n  geom_point(shape = 21) + \n  scale_fill_gradient2(limits = c(-1,1)\n    , breaks = c(-1, -.5, 0, .5, 1)\n    , low = \"blue\", high = \"red\"\n    , mid = \"white\", na.value = \"white\") + \n  scale_size_continuous(range = c(3,14)) + \n  labs(\n    x = NULL\n    , y = NULL\n    , fill = \"Zero-Order Correlation\"\n    , title = \"Zero-Order Correlations Among Variables\"\n    , subtitle = \"Sample 1\"\n    ) + \n  guides(size = \"none\") + \n  theme_classic() + \n  theme(\n    legend.position = \"bottom\"\n    , axis.text = element_text(face = \"bold\")\n    , axis.text.x = element_text(angle = 45, hjust = 1)\n    , plot.title = element_text(face = \"bold\", hjust = .5)\n    , plot.subtitle = element_text(face = \"italic\", hjust = .5)\n    , panel.background = element_rect(color = \"black\", size = 1)\n  )\n```\n\n# Part 2 Visualizing Associations, Parameters, and Predictions from Models\n\n-   The goal of data visualization is to tell a story that tables, words, etc. either can't or can't do simply\n-   Data visualizations aims to clarify complex patterns in data\n-   Thus far, we've mostly focused on building models from raw data or descriptives of raw data\n-   But in most research, we lean on inferential statistics and hypothesis testing (frequent or Bayesian) to tell our story\n-   So next, we'll talk about how to use data visualization to tell stories *with* models\n    -   The reality is that there is no generalizable way to do this\n    -   So we will focus on models for which we are interested in specific parameters and/or parameterized our questions\n    -   Why? These have some shared functions across *lots* of packages in R\n    -   For models that don't, that's a data cleaning problem, not a visualization problem\n-   Let's start with a basic model and predict later all-cause mortality from Conscientiousness in Sample 1.\\\n-   The basic form of the model is:\n\n$$\nlogit(\\frac{\\pi}{1-\\pi}) = b_0 + b_1*C_{ij} + \\epsilon_{ij}\n$$\n\n```{r}\nds1 <- pred_data %>% filter(study == \"Study1\")\nm1 <- glm(o_value ~ p_value, data = ds1, family = binomial(link = \"logit\"))\nsummary(m1)\n```\n\n-   Models and other objects in `R` are stored in lists or list-like objects\n-   We can explore these lots of ways, but one good one is with `str()`\n\n```{r}\nstr(m1)\n```\n\n-   The `broom` package is great for working with models (and the `broom.mixed` add-on makes it even better)\n-   We're going to talk about how three its functions can be used for / improve data visualization:\n    -   `tidy()`\n    -   `glance()`\n    -   `augment()`\n\n## Models + `broom`: `tidy()`\n\n-   Outside of `dplyr`/`tidyr`, `tidy()` is a close contender with `purrr::map()` functions as my most used function\n-   Why?\n    -   When you run a model, base `R` provides the `summary()`, `coef()`, etc. to extract various components of the model\n    -   But these aren't `data.frames`, which are core input to a lot of other `R` functions across packages\n    -   `tidy()` provides a data frame with core model coefficients, inferential tests, etc. that be easily matched and merged across models, etc.\n-   But with logistic regression with a logit link, we are left with coefficents that have to be interpreted in log odds, which realistically, almost no one can do\n-   So we have to \"undo\" the log, which you may remember can done by exponentiating the natural log (ln)\n-   But we can directly exponentiate from the summary function because it's the wrong class of object\n-   We could just exponentiate the coefficients from the `coef()` function, but this still leaves us with the need to extract estimates of precision, like standard errors, confidence intervals, and more.\n\n```{r}\ncoef(m1)\n```\n\n-   Enter `broom::tidy()`!\n\n```{r}\ntidy(m1)\n```\n\n-   Even better, we can easily get confidence intervals\n\n```{r}\ntidy(m1, conf.int = T)\n```\n\n### Multiple Parameter Plots\n\n-   But when would you ever want to create a plot of just two parameters? Maybe never, but what if we wanted to do it for all 6 samples?\n-   Watch! Let's make a nested data frame that will hold\n    -   All the data for each sample\n    -   A model for each sample\n    -   The `tidy()` data frame of the parmeter estimates for each sample\n\n```{r}\ntidy_ci <- function(m) tidy(m, conf.int = T)\n\nnested_m <- pred_data %>%\n  group_by(study) %>%\n  nest() %>%\n  ungroup() %>%\n  mutate(\n    m = map(data, ~glm(o_value ~p_value, data = ., family = binomial(link = \"logit\")))\n    , tidy = map(m, tidy_ci)\n  )\nnested_m\n```\n\nNow, we'll drop the `data` and `m` columns that we don't need and `unnest()` our `tidy()` data frames\n\n```{r}\nnested_m %>%\n  select(study, tidy) %>%\n  unnest(tidy)\n```\n\n### Basic Plot\n\nNow these parameters from multiple models, we may want to plot!\n\n```{r}\nnested_m %>%\n  select(study, tidy) %>%\n  unnest(tidy) %>%\n  mutate_at(vars(estimate, conf.low, conf.high), exp) %>%\n  ggplot(\n    aes(y = study, x = estimate)\n  ) + \n    geom_errorbar(\n      aes(xmin = conf.low, xmax = conf.high)\n      , position = position_dodge(width = .9)\n      , width = .1\n      ) + \n    geom_point() + \n    theme_classic()\n```\n\n#### Faceting\n\nAlmost, but we have two parameters for each model (Intercept and p_value), so let's split those in a facet:\n\n```{r}\nnested_m %>%\n  select(study, tidy) %>%\n  unnest(tidy) %>%\n  mutate_at(vars(estimate, conf.low, conf.high), exp) %>%\n  ggplot(\n    aes(y = study, x = estimate)\n  ) + \n    geom_errorbar(\n      aes(xmin = conf.low, xmax = conf.high)\n      , position = position_dodge(width = .9)\n      , width = .1\n      ) + \n    geom_point() + \n    facet_grid(~term) + \n    theme_classic()\n```\n\nWe've got some work to do to make this an intuitive figure. Let's: + Add a dashed line at 1 (odd ratio of 1 is a null effect) + Make the points bigger + Fix the titles on the plot and axis titles + Add some color + Fiddle with themes to make it prettier\n\n#### Null Comparison\n\nAdd a dashed line at 1 (odd ratio of 1 is a null effect)\n\n```{r}\nnested_m %>%\n  select(study, tidy) %>%\n  unnest(tidy) %>%\n  mutate_at(vars(estimate, conf.low, conf.high), exp) %>%\n  ggplot(\n    aes(y = study, x = estimate)\n  ) + \n    geom_vline(aes(xintercept = 1), linetype = \"dashed\") + \n    geom_errorbar(\n      aes(xmin = conf.low, xmax = conf.high)\n      , position = position_dodge(width = .9)\n      , width = .1\n      ) + \n    geom_point() + \n    facet_grid(~term, scales = \"free\") + \n    theme_classic()\n```\n\n#### Point Size\n\n-   Make the points bigger\n\n```{r}\nnested_m %>%\n  select(study, tidy) %>%\n  unnest(tidy) %>%\n  mutate_at(vars(estimate, conf.low, conf.high), exp) %>%\n  ggplot(\n    aes(y = study, x = estimate)\n  ) + \n    geom_vline(aes(xintercept = 1), linetype = \"dashed\") + \n    geom_errorbar(\n      aes(xmin = conf.low, xmax = conf.high)\n      , position = position_dodge(width = .9)\n      , width = .1\n      ) + \n    geom_point(size = 3, shape = 15) + \n    facet_grid(~term, scales = \"free\") + \n    theme_classic()\n```\n\n#### Titles\n\n-   Fix the titles on the plot and axis titles\n\n```{r}\nnested_m %>%\n  select(study, tidy) %>%\n  unnest(tidy) %>%\n  mutate_at(vars(estimate, conf.low, conf.high), exp) %>%\n  ggplot(\n    aes(y = study, x = estimate)\n  ) + \n    geom_vline(aes(xintercept = 1), linetype = \"dashed\") + \n    geom_errorbar(\n      aes(xmin = conf.low, xmax = conf.high)\n      , position = position_dodge(width = .9)\n      , width = .1\n      ) + \n    geom_point(size = 3, shape = 15) + \n    labs(\n      x = \"Estimate (CI) in OR\"\n      , y = NULL\n      , title = \"Conscientiousness was associated with mortality 50% of samples\"\n      , subtitle = \"Samples with lower mortality risk overall had fewer significant associations\"\n      ) + \n    facet_grid(~term, scales = \"free\") + \n    theme_classic()\n```\n\n#### Color and Themes\n\nAdd some color Fiddle with themes to make it prettier\n\n```{r}\nnested_m %>%\n  select(study, tidy) %>%\n  unnest(tidy) %>%\n  mutate_at(vars(estimate, conf.low, conf.high), exp) %>%\n  ggplot(\n    aes(y = study, x = estimate, fill = study)\n  ) + \n    geom_vline(aes(xintercept = 1), linetype = \"dashed\") + \n    geom_errorbar(\n      aes(xmin = conf.low, xmax = conf.high)\n      , position = position_dodge(width = .9)\n      , width = .1\n      ) + \n    geom_point(size = 3, shape = 22) + \n    labs(\n      x = \"Estimate (CI) in OR\"\n      , y = NULL\n      , title = \"Conscientiousness was associated with mortality 50% of samples\"\n      , subtitle = \"Samples with lower mortality risk overall had fewer significant associations\"\n      ) + \n    facet_grid(~term, scales = \"free\") + \n    theme_classic() + \n    theme(\n      legend.position = \"none\"\n      , axis.text = element_text(face = \"bold\", size = rel(1.1))\n      , axis.title = element_text(face = \"bold\", size = rel(1.2))\n      , axis.line = element_blank()\n      , strip.text = element_text(face = \"bold\", size = rel(1.1), color = \"white\")\n      , strip.background = element_rect(fill = \"black\")\n      , plot.title = element_text(face = \"bold\", size = rel(1.1), hjust = .5)\n      , plot.subtitle = element_text(face = \"italic\", size = rel(1.1))\n      , panel.border = element_rect(color = \"black\", fill = NA, size = 1)\n    )\n```\n\n-   This isn't perfect. But we're going to come back to this kind of plot when we talk about \"piecing plots together.\"\n-   Personally, I would:\n    -   Add text with Est. (CI) and N for each sample in the figure\n    -   Build both of these separately in order to order by effect size\n    -   Then put them back together and re-add the title\n\n## Models + `broom`: `glance()`\n\n-   When we run models, we need to care about more that just point and interval estimates\n-   Often we are interested in comparing models, checking diagnostics, etc.\n-   Again, all of these are embedded (mostly), in the model objects\n-   The `glance()` function brings some of these important ones into a single object\n-   Here's what it gives us for our logistic regression model\n\n```{r}\nglance(m1)\n```\n\n-   Let's also look for al linear model, which may be more familiar for many of you:\n\n```{r}\nm2 <- lm(SRhealth ~ age, data = ds1)\nglance(m2)\n```\n\nAs before, we can do this with lots of models to compare across samples:\n\n```{r}\nnested_m <- nested_m %>%\n  mutate(glance = map(m, glance))\nnested_m\n```\n\n```{r}\nnested_m %>%\n  select(study, glance) %>%\n  unnest(glance)\n```\n\nRealistically, this is the kind of info we table, but we can also merge it with info from tidy:\n\n```{r}\nnested_m %>%\n  select(-data, -m) %>%\n  unnest(tidy) %>% \n  unnest(glance) %>%\n  mutate_if(is.numeric, ~round(., 2))\n```\n\n-   Diagnostics are not just summary statistics!\n-   We care a lot about prediction, too\n    -   Residuals both tell us unexplained variance (i.e. how observed data deviate from model predictions)\n    -   Model predictions and prediction intervals tell us about how our model is doing across levels our variables\n\nLet's keep working with our nested data frame. Remember, it looks like this:\n\n```{r}\nnested_m\n```\n\n## Models + `broom`: `augment()`\n\n-   `augment()` let's us add (augment) the raw data we feed the model based on the fitted model\n-   Notice we now have more columns\n\n```{r}\nnested_m <- nested_m %>%\n  mutate(data = map2(m, data, augment, se_fit = T))\nnested_m\n```\n\n### `glm()` + `augment()`\n\n-   Here's the columns we used along with the additional columns with a `glm`:\n    -   `.fitted`: fitted / predicted value\n    -   `.se.fit`: standard error\n    -   `.resid`: observed - fitted\n    -   `.std.resd`: standardized residuals\n    -   `.sigma`: estimated residual SD when this obs is dropped from model\n    -   `cooksd`: Cooks distance (is this an outlier?)\n\n```{r}\nnested_m$data[[1]] %>%\n  select(o_value, SID, p_value, .fitted:.cooksd)\n```\n\n### `lm()` + `augment()`\n\nFor the most part, many of the checks with `glm`'s and `lm`'s are the same. But it's a bit easier to wrap your head around `lm()`, so let's switch to that:\n\n```{r}\nnested_lm <- pred_data %>%\n  select(study, SID, p_value, age, SRhealth) %>%\n  drop_na() %>%\n  group_by(study) %>%\n  nest() %>%\n  ungroup() %>%\n  mutate(m = map(data, ~lm(SRhealth ~ p_value + age, data = .))\n         , tidy = map(m, tidy_ci)\n         , glance = map(m, glance)\n         , data = map2(m, data, augment, se_fit = T, interval = \"confidence\"))\nnested_lm\n```\n\n-   Here's the columns we used along with the additional columns with an `lm`:\n    -   `.fitted`: fitted / predicted value\n    -   `.se.fit`: standard error\n    -   `.lower`: lower bound of the confidence/prediction interval\n    -   `.upper`: upper bound of the confidence/prediction interval\n    -   `.resid`: observed - fitted\n    -   `.std.resd`: standardized residuals\n    -   `.sigma`: estimated residual SD when this obs is dropped from model\n    -   `cooksd`: Cooks distance (is this an outlier?)\n-   One standard diagnostic plot is to plot fitted values v residuals\n-   Looks a little wonky (remember, these are results from multiple harmonized studies)\n\n```{r}\nnested_lm %>%\n  select(study, data) %>%\n  unnest(data) %>%\n  ggplot(aes(\n    x = .fitted\n    , y = .resid\n  )) + \n  geom_point() + \n  theme_classic()\n```\n\n### Plotting `augment()` Diagnostics\n\n-   One standard diagnostic plot is to plot fitted values v residuals\n-   Looks a little wonky (remember, these are results from multiple harmonized studies)\n\n```{r}\nnested_lm %>%\n  select(study, data) %>%\n  unnest(data) %>%\n  ggplot(aes(\n    x = .fitted\n    , y = .resid\n  )) + \n  geom_point() +\n  labs(\n    x = \"Model Fitted Values\"\n    , y = \"Residual\") +\n  facet_wrap(~study) + \n  theme_classic()\n```\n\n## Models + `broom`: `augment()`\n\nAnother is raw v. fitted\n\n```{r}\nnested_lm %>%\n  select(study, data) %>%\n  unnest(data) %>%\n  ggplot(aes(\n    x = p_value\n    , y = .resid\n  )) + \n  geom_point() +\n  facet_wrap(~study) + \n  theme_classic()\n```\n\n### Model Predictions\n\n-   Although we can get the standard error of the prediction for each person, we often want to look at theoretical predictions, adjusting for covariates. We can typically use built-in `predict()` or `fitted()` functions\n-   To do this, we need to see theoretical ranges of key variables and grab averages of covariates\n-   I use functions for this. We'll do one and build\n\n```{r}\nm1 <- nested_lm$m[[1]]\nd1 <- m1$model\n\ncrossing(\n  p_value = seq(0, 10, length.out = 100)\n  , age = mean(d1$age)\n) %>%\n  bind_cols(\n    .\n    , predict(m1, newdata = ., interval = \"prediction\")\n  )\n```\n\n#### Plotting That\n\n```{r}\ncrossing(\n  p_value = seq(0, 10, .1)\n  , age = mean(d1$age)\n) %>%\n  bind_cols(\n    .\n    , predict(m1, newdata = ., interval = \"prediction\")\n  ) %>%\n  ggplot(aes(x = p_value, y = fit)) + \n    geom_ribbon(aes(ymin = lwr, ymax = upr), fill = \"seagreen4\", alpha = .2) + \n    geom_line(color = \"seagreen4\", size = 2) + \n    theme_classic()\n```\n\n-   This is fine, but it could use some improvements:\n    -   better scales\n    -   raw data\n    -   the usual aesthetics\n\n#### Better scales\n\n```{r}\ncrossing(\n  p_value = seq(0, 10, .1)\n  , age = mean(d1$age)\n) %>%\n  bind_cols(\n    .\n    , predict(m1, newdata = ., interval = \"prediction\")\n  ) %>%\n  ggplot(aes(x = p_value, y = fit)) + \n    geom_ribbon(aes(ymin = lwr, ymax = upr), fill = \"seagreen4\", alpha = .2) + \n    geom_line(color = \"seagreen4\", size = 2) + \n    scale_x_continuous(limits = c(0,10.2), breaks = seq(0,10,2)) + \n    scale_y_continuous(limits = c(0,10.2), breaks = seq(0,10,2)) + \n    theme_classic()\n```\n\n#### Raw Data\n\n```{r}\ncrossing(\n  p_value = seq(0, 10, .1)\n  , age = mean(d1$age)\n) %>%\n  bind_cols(., predict(m1, newdata = ., interval = \"prediction\")) %>%\n  ggplot(aes(x = p_value, y = fit)) + \n    geom_point(\n      data = d1\n      , aes(x = p_value, y = SRhealth)\n      , alpha = .4\n      , color = \"seagreen4\"\n      ) + \n    geom_ribbon(aes(ymin = lwr, ymax = upr), fill = \"seagreen4\", alpha = .2) + \n    geom_line(color = \"seagreen4\", size = 2) + \n    scale_x_continuous(limits = c(0,10.2), breaks = seq(0,10,2)) + \n    scale_y_continuous(limits = c(0,10.2), breaks = seq(0,10,2)) + \n    theme_classic()\n```\n\n#### The usual aesthetics\n\n```{r}\ncrossing(\n  p_value = seq(0, 10, .1)\n  , age = mean(d1$age)\n) %>%\n  bind_cols(., predict(m1, newdata = ., interval = \"prediction\")) %>%\n  ggplot(aes(x = p_value, y = fit)) + \n    geom_point(data = d1, aes(x = p_value, y = SRhealth)\n      , alpha = .4, color = \"seagreen4\") + \n    geom_ribbon(aes(ymin = lwr, ymax = upr), fill = \"seagreen4\", alpha = .2) + \n    geom_line(color = \"seagreen4\", size = 2) + \n    scale_x_continuous(limits = c(0,10.2), breaks = seq(0,10,2)) + \n    scale_y_continuous(limits = c(0,10.2), breaks = seq(0,10,2)) + \n    labs(\n      x = \"Conscientiousness (POMP; 0-10)\"\n      , y = \"Predicted Self-Rated Health (POMP; 0-10)\"\n      , title = \"Conscientiousness and Self-Rated Health\\nWere Weakly Associated\"\n      ) + \n    theme_classic() + \n    theme(\n      axis.text = element_text(face = \"bold\", size = rel(1.1))\n      , axis.title = element_text(face = \"bold\", size = rel(1.1))\n      , plot.title = element_text(face = \"bold\", size = rel(1.2), hjust = .5)\n      )\n```\n\n#### Now let's do it for all of the samples\n\n```{r}\npred_fun <- function(m){\n  d <- m$model\n\n  crossing(\n    p_value = seq(0, 10, length.out = 100)\n    , age = mean(d$age)\n  ) %>%\n    bind_cols(\n      .\n      , predict(m, newdata = ., interval = \"prediction\")\n    )\n}\n\nnested_lm <- nested_lm %>%\n  mutate(pred = map(m, pred_fun))\nnested_lm\n```\n\nNow let's do it for all of the samples\n\n```{r}\nnested_lm %>%\n  select(study, pred) %>%\n  unnest(pred)\n```\n\n-   Now let's do it for all of the samples\n-   Very close, but our intervals are cutoff\n\n```{r}\nnested_lm %>%\n  select(study, pred) %>%\n  unnest(pred) %>%\n  ggplot(aes(x = p_value, y = fit)) + \n    geom_point(data = d1, aes(x = p_value, y = SRhealth)\n      , alpha = .2, color = \"seagreen4\") + \n    geom_ribbon(aes(ymin = lwr, ymax = upr), fill = \"seagreen4\", alpha = .2) + \n    geom_line(color = \"seagreen4\", size = 2) + \n    scale_x_continuous(limits = c(0,10.2), breaks = seq(0,10,2)) + \n    scale_y_continuous(limits = c(0,10.2), breaks = seq(0,10,2)) + \n    labs(\n      x = \"Conscientiousness (POMP; 0-10)\"\n      , y = \"Predicted Self-Rated Health (POMP; 0-10)\"\n      , title = \"Conscientiousness and Self-Rated Health\\nWere Weakly Associated In Most Samples\"\n      ) + \n    facet_wrap(~study, ncol = 2) + \n    theme_classic() + \n    theme(\n      axis.text = element_text(face = \"bold\", size = rel(1.1))\n      , axis.title = element_text(face = \"bold\", size = rel(1.1))\n      , plot.title = element_text(face = \"bold\", size = rel(1.2), hjust = .5)\n      )\n```\n\n-   Now let's do it for all of the samples\n-   Very close, but our intervals are cutoff\n\n```{r}\nnested_lm %>%\n  select(study, pred) %>%\n  unnest(pred) %>%\n  mutate(upr = ifelse(upr > 10, 10, upr)\n         , lwr = ifelse(lwr < 0, 0, lwr)) %>%\n  ggplot(aes(x = p_value, y = fit)) + \n    geom_point(data = d1, aes(x = p_value, y = SRhealth)\n      , alpha = .2, color = \"seagreen4\") + \n    geom_ribbon(aes(ymin = lwr, ymax = upr), fill = \"seagreen4\", alpha = .2) + \n    geom_line(color = \"seagreen4\", size = 2) + \n    scale_x_continuous(limits = c(0,10.2), breaks = seq(0,10,2)) + \n    scale_y_continuous(limits = c(0,10.2), breaks = seq(0,10,2)) + \n    labs(\n      x = \"Conscientiousness (POMP; 0-10)\"\n      , y = \"Predicted Self-Rated Health (POMP; 0-10)\"\n      , title = \"Conscientiousness and Self-Rated Health\\nWere Weakly Associated In Most Samples\"\n      ) + \n    facet_wrap(~study, ncol = 2) + \n    theme_classic() + \n    theme(\n      axis.text = element_text(face = \"bold\", size = rel(1.1))\n      , axis.title = element_text(face = \"bold\", size = rel(1.1))\n      , plot.title = element_text(face = \"bold\", size = rel(1.2), hjust = .5)\n      , strip.background = element_rect(fill = \"darkseagreen4\")\n      , strip.text = element_text(face = \"bold\", color = \"white\")\n      )\n```\n\n## Wrapping Up\n\n-   This is a quick introduction to visualizing associations and working with models\n-   Here, we focused on doing things very manually to promote understanding\n-   But there are lots of packages to automate much of this\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"paged","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"show","code-overflow":"scroll","code-link":true,"code-line-numbers":true,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"highlight-style":"tango","self-contained":true,"output-file":"04-week4-workbook.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","editor":"visual","theme":["cosmo","custom-styles.scss"],"title":"Week 4 (Workbook) - Associations","author":"Emorie D Beck","code-copy":true,"toc-float":true,"footer":"PSC 290 - Data Visualization","logo":"https://github.com/emoriebeck/psc290-data-viz-2022/raw/main/01-week1-intro/02-code/02-images/ucdavis_logo_blue.png"},"extensions":{"book":{"multiFile":true}}}}}